{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
      "2   0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
      "3   0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
      "4   0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
      "5   0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
      "\n",
      "   var7(t-1)  var8(t-1)   var1(t)  \n",
      "1   0.000000        0.0  0.148893  \n",
      "2   0.000000        0.0  0.159960  \n",
      "3   0.000000        0.0  0.182093  \n",
      "4   0.037037        0.0  0.138833  \n",
      "5   0.074074        0.0  0.109658  \n",
      "(8760, 1, 8) (8760,) (35039, 1, 8) (35039,)\n",
      "Train on 8760 samples, validate on 35039 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.0590 - val_loss: 0.0458\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.0399 - val_loss: 0.0382\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.0233 - val_loss: 0.0322\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.0177 - val_loss: 0.0314\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.0162 - val_loss: 0.0207\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.0151 - val_loss: 0.0167\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.0147 - val_loss: 0.0155\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.0146 - val_loss: 0.0150\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0142\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0139\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.0144 - val_loss: 0.0139\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.0145 - val_loss: 0.0138\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0137\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.0146 - val_loss: 0.0137\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.0143 - val_loss: 0.0136\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0137\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.0142 - val_loss: 0.0136\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0136\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.0144 - val_loss: 0.0136\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.0144 - val_loss: 0.0136\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0141\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.0144 - val_loss: 0.0136\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.0143 - val_loss: 0.0136\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.0144 - val_loss: 0.0136\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0135\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.0145 - val_loss: 0.0136\n"
     ]
    }
   ],
   "source": [
    "# convert series to supervised learning\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import concatenate, sqrt\n",
    "from pandas import concat, DataFrame, read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "\n",
    "# load dataset\n",
    "dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:, 4] = encoder.fit_transform(values[:, 4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9, 10, 11, 12, 13, 14, 15]], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
